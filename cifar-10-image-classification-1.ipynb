{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications import VGG16, VGG19, ResNet50, DenseNet121\nfrom tensorflow.keras.layers import Input,Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:42:54.223006Z","iopub.execute_input":"2023-11-02T06:42:54.223788Z","iopub.status.idle":"2023-11-02T06:42:54.230683Z","shell.execute_reply.started":"2023-11-02T06:42:54.223752Z","shell.execute_reply":"2023-11-02T06:42:54.229729Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, GlobalAveragePooling2D, Dense","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:42:54.236821Z","iopub.execute_input":"2023-11-02T06:42:54.237378Z","iopub.status.idle":"2023-11-02T06:42:54.247226Z","shell.execute_reply.started":"2023-11-02T06:42:54.237350Z","shell.execute_reply":"2023-11-02T06:42:54.246131Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"\n\n# Load CIFAR-10 dataset\n(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n\n# Preprocess the data\ntrain_images = train_images / 255.0\ntest_images = test_images / 255.0\ntrain_labels = to_categorical(train_labels, num_classes=10)\ntest_labels = to_categorical(test_labels, num_classes=10)\n\n# Data augmentation for the training set\ndatagen = ImageDataGenerator(\n    rotation_range=20,          # Randomly rotate images in the range (-20, 20) degrees\n    width_shift_range=0.1,      # Randomly shift images horizontally by up to 10% of the width\n    height_shift_range=0.1,     # Randomly shift images vertically by up to 10% of the height\n    horizontal_flip=True,       # Randomly flip images horizontally\n    zoom_range=0.1,             # Randomly zoom in/out by up to 10%\n    fill_mode='nearest',        # Filling mode for new pixels created after rotation or shifting\n    cval=0,                     # Value used for points outside the boundaries with constant fill mode\n    rescale=None,               # Rescaling factor, if any (no need since we already scaled the data)\n    preprocessing_function=None  # Optional custom preprocessing function\n)\n\n# Fit the augmenter to your data\ndatagen.fit(train_images)\n\n# Generate augmented data\naugmented_data = datagen.flow(train_images, train_labels, batch_size=64)\n\n# Example: To get a batch of augmented data\nbatch_images, batch_labels = next(augmented_data)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:42:54.249089Z","iopub.execute_input":"2023-11-02T06:42:54.249490Z","iopub.status.idle":"2023-11-02T06:42:56.124115Z","shell.execute_reply.started":"2023-11-02T06:42:54.249454Z","shell.execute_reply":"2023-11-02T06:42:56.123117Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"# Define the learning rate schedule\ndef lr_schedule(epoch):\n    if epoch < 200:\n        return 0.1\n    elif epoch < 400:\n        return 0.01\n    else:\n        return 0.001\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:42:56.125243Z","iopub.execute_input":"2023-11-02T06:42:56.125538Z","iopub.status.idle":"2023-11-02T06:42:56.130484Z","shell.execute_reply.started":"2023-11-02T06:42:56.125512Z","shell.execute_reply":"2023-11-02T06:42:56.129549Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, GlobalAveragePooling2D, Dense\n\ndef create_base_net(num_layers=20):\n    input_layer = Input(shape=(32, 32, 3))\n    \n    x = Conv2D(16, (3, 3), padding='same', activation='relu')(input_layer)\n    \n    # Define the number of convolution layers per module\n    num_layers_per_module = [6, 6, 6]  # You can adjust these as needed\n    \n    in_channels = 16\n    \n    for num_layers in num_layers_per_module:\n        for _ in range(num_layers):\n            x = Conv2D(in_channels, (3, 3), padding='same', activation='relu')(x)\n            x = BatchNormalization()(x)\n        \n        in_channels *= 2  # Double the number of channels after each module\n    \n    x = GlobalAveragePooling2D()(x)\n    output_layer = Dense(10, activation='softmax')(x)\n    \n    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n    \n    return model\n\n# Usage:\nmodel_base_20 = create_base_net(num_layers=20)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:42:56.133263Z","iopub.execute_input":"2023-11-02T06:42:56.134143Z","iopub.status.idle":"2023-11-02T06:42:56.536656Z","shell.execute_reply.started":"2023-11-02T06:42:56.134096Z","shell.execute_reply":"2023-11-02T06:42:56.535638Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"# Train and evaluate BaseNet-20\nmodel_base_20 = create_base_net(num_layers=20)\nmodel_base_20.compile(optimizer=SGD(learning_rate=0.1, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_base_20.fit(train_images, train_labels, batch_size=64, epochs=10, callbacks=[LearningRateScheduler(lr_schedule)])\nscores_base_20 = model_base_20.evaluate(train_images, train_labels, verbose=0)\nprint(\"BaseNet-20 Training Accuracy:\", scores_base_20[1])\nprint(\"BaseNet-20 Training Loss:\", scores_base_20[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:42:56.538024Z","iopub.execute_input":"2023-11-02T06:42:56.538339Z","iopub.status.idle":"2023-11-02T06:46:31.739837Z","shell.execute_reply.started":"2023-11-02T06:42:56.538312Z","shell.execute_reply":"2023-11-02T06:46:31.738732Z"},"trusted":true},"execution_count":136,"outputs":[{"name":"stdout","text":"Epoch 1/10\n782/782 [==============================] - 27s 25ms/step - loss: 2.0916 - accuracy: 0.2069 - lr: 0.1000\nEpoch 2/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0396 - accuracy: 0.2207 - lr: 0.1000\nEpoch 3/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0172 - accuracy: 0.2300 - lr: 0.1000\nEpoch 4/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0136 - accuracy: 0.2311 - lr: 0.1000\nEpoch 5/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0158 - accuracy: 0.2302 - lr: 0.1000\nEpoch 6/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0124 - accuracy: 0.2305 - lr: 0.1000\nEpoch 7/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0176 - accuracy: 0.2283 - lr: 0.1000\nEpoch 8/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.0261 - accuracy: 0.2267 - lr: 0.1000\nEpoch 9/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0407 - accuracy: 0.2240 - lr: 0.1000\nEpoch 10/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0386 - accuracy: 0.2228 - lr: 0.1000\nBaseNet-20 Training Accuracy: 0.11971999704837799\nBaseNet-20 Training Loss: 3.1175012588500977\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate BaseNet-20 on the testing data with integer labels\ntest_loss_base_20, test_acc_base_20 = model_base_20.evaluate(test_images, test_labels, verbose=2)\nprint(f'BaseNet-20 Testing Accuracy: {test_acc_base_20:.4f}')\nprint(f'BaseNet-20 Testing Loss: {test_loss_base_20:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:46:31.741160Z","iopub.execute_input":"2023-11-02T06:46:31.741451Z","iopub.status.idle":"2023-11-02T06:46:33.576113Z","shell.execute_reply.started":"2023-11-02T06:46:31.741425Z","shell.execute_reply":"2023-11-02T06:46:33.575280Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stdout","text":"313/313 - 1s - loss: 3.1207 - accuracy: 0.1200 - 1s/epoch - 5ms/step\nBaseNet-20 Testing Accuracy: 0.1200\nBaseNet-20 Testing Loss: 3.1207\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train and evaluate BaseNet-32\nmodel_base_32 = create_base_net(num_layers=32)\nmodel_base_32.compile(optimizer=SGD(learning_rate=0.1, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_base_32.fit(train_images, train_labels, batch_size=64, epochs=10, callbacks=[LearningRateScheduler(lr_schedule)])\nscores_base_32 = model_base_32.evaluate(train_images, train_labels, verbose=0)\nprint(\"BaseNet-32 Training Accuracy:\", scores_base_32[1])\nprint(\"BaseNet-32 Training Loss:\", scores_base_32[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:46:33.577505Z","iopub.execute_input":"2023-11-02T06:46:33.577820Z","iopub.status.idle":"2023-11-02T06:50:10.113436Z","shell.execute_reply.started":"2023-11-02T06:46:33.577793Z","shell.execute_reply":"2023-11-02T06:50:10.112362Z"},"trusted":true},"execution_count":138,"outputs":[{"name":"stdout","text":"Epoch 1/10\n782/782 [==============================] - 24s 25ms/step - loss: 2.0851 - accuracy: 0.2134 - lr: 0.1000\nEpoch 2/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0125 - accuracy: 0.2233 - lr: 0.1000\nEpoch 3/10\n782/782 [==============================] - 19s 25ms/step - loss: 1.9728 - accuracy: 0.2342 - lr: 0.1000\nEpoch 4/10\n782/782 [==============================] - 19s 25ms/step - loss: 1.9885 - accuracy: 0.2340 - lr: 0.1000\nEpoch 5/10\n782/782 [==============================] - 20s 25ms/step - loss: 1.9555 - accuracy: 0.2459 - lr: 0.1000\nEpoch 6/10\n782/782 [==============================] - 20s 25ms/step - loss: 1.9343 - accuracy: 0.2541 - lr: 0.1000\nEpoch 7/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0059 - accuracy: 0.2336 - lr: 0.1000\nEpoch 8/10\n782/782 [==============================] - 19s 25ms/step - loss: 1.9998 - accuracy: 0.2359 - lr: 0.1000\nEpoch 9/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.0023 - accuracy: 0.2413 - lr: 0.1000\nEpoch 10/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.0018 - accuracy: 0.2436 - lr: 0.1000\nBaseNet-32 Training Accuracy: 0.21143999695777893\nBaseNet-32 Training Loss: 2.2035739421844482\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate BaseNet-20 on the testing data with integer labels\ntest_loss_base_32, test_acc_base_32 = model_base_32.evaluate(test_images, test_labels, verbose=2)\nprint(f'BaseNet-32 Testing Accuracy: {test_acc_base_32:.4f}')\nprint(f'BaseNet-32 Testing Loss: {test_loss_base_32:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:50:10.114611Z","iopub.execute_input":"2023-11-02T06:50:10.114952Z","iopub.status.idle":"2023-11-02T06:50:11.953222Z","shell.execute_reply.started":"2023-11-02T06:50:10.114926Z","shell.execute_reply":"2023-11-02T06:50:11.952233Z"},"trusted":true},"execution_count":139,"outputs":[{"name":"stdout","text":"313/313 - 1s - loss: 2.2216 - accuracy: 0.2147 - 1s/epoch - 5ms/step\nBaseNet-32 Testing Accuracy: 0.2147\nBaseNet-32 Testing Loss: 2.2216\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, GlobalAveragePooling2D, Dense, Add\n\ndef residual_block(x, filters, stride=1):\n    shortcut = x\n    x = Conv2D(filters, (3, 3), strides=stride, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(filters, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    \n    if shortcut.shape[1:] != x.shape[1:]:\n        shortcut = Conv2D(filters, (1, 1), strides=stride, padding='valid')(shortcut)\n    \n    x = Add()([x, shortcut])\n    x = Activation('relu')(x)\n    \n    return x\n\ndef create_resnet(num_layers=20):\n    input_layer = Input(shape=(32, 32, 3))\n    \n    x = Conv2D(16, (3, 3), padding='same', activation='relu')(input_layer)\n    \n    num_modules = 3\n    num_blocks_per_module = 3\n    \n    in_channels = 16\n    \n    for module in range(num_modules):\n        for block in range(num_blocks_per_module):\n            x = residual_block(x, in_channels)\n        in_channels *= 2\n    \n    x = GlobalAveragePooling2D()(x)\n    output_layer = Dense(10, activation='softmax')(x)\n    \n    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n    \n    return model\n\n# Usage:\nmodel_resnet_20 = create_resnet(num_layers=20)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:50:11.956026Z","iopub.execute_input":"2023-11-02T06:50:11.956308Z","iopub.status.idle":"2023-11-02T06:50:12.435571Z","shell.execute_reply.started":"2023-11-02T06:50:11.956284Z","shell.execute_reply":"2023-11-02T06:50:12.434784Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"# Train and evaluate ResNet-20\nmodel_resnet_20 = create_resnet(num_layers=20)\nmodel_resnet_20.compile(optimizer=SGD(learning_rate=0.1, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_resnet_20.fit(train_images, train_labels, batch_size=64, epochs=10, callbacks=[LearningRateScheduler(lr_schedule)])\nscores_resnet_20 = model_resnet_20.evaluate(train_images, train_labels, verbose=0)\nprint(\"ResNet-20 Training Accuracy:\", scores_resnet_20[1])\nprint(\"ResNet-20 Training Loss:\", scores_resnet_20[0])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:50:12.436606Z","iopub.execute_input":"2023-11-02T06:50:12.436893Z","iopub.status.idle":"2023-11-02T06:54:10.148265Z","shell.execute_reply.started":"2023-11-02T06:50:12.436869Z","shell.execute_reply":"2023-11-02T06:54:10.147310Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"Epoch 1/10\n782/782 [==============================] - 27s 28ms/step - loss: 1.7288 - accuracy: 0.3516 - lr: 0.1000\nEpoch 2/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.2668 - accuracy: 0.5390 - lr: 0.1000\nEpoch 3/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.0307 - accuracy: 0.6289 - lr: 0.1000\nEpoch 4/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.9080 - accuracy: 0.6769 - lr: 0.1000\nEpoch 5/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.8190 - accuracy: 0.7118 - lr: 0.1000\nEpoch 6/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.7480 - accuracy: 0.7362 - lr: 0.1000\nEpoch 7/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.6938 - accuracy: 0.7573 - lr: 0.1000\nEpoch 8/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.6351 - accuracy: 0.7768 - lr: 0.1000\nEpoch 9/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.5988 - accuracy: 0.7924 - lr: 0.1000\nEpoch 10/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.5644 - accuracy: 0.8028 - lr: 0.1000\nResNet-20 Training Accuracy: 0.7120400071144104\nResNet-20 Training Loss: 0.8932788968086243\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate ResNet-20 on the testing data with integer labels\ntest_loss_resnet_20, test_acc_resnet_20 = model_resnet_20.evaluate(test_images, test_labels, verbose=2)\nprint(f'ResNet-20 Testing Accuracy: {test_acc_resnet_20:.4f}')\nprint(f'ResNet-20 Testing Loss: {test_loss_resnet_20:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:54:10.149547Z","iopub.execute_input":"2023-11-02T06:54:10.149875Z","iopub.status.idle":"2023-11-02T06:54:12.202562Z","shell.execute_reply.started":"2023-11-02T06:54:10.149847Z","shell.execute_reply":"2023-11-02T06:54:12.201548Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"313/313 - 2s - loss: 1.0231 - accuracy: 0.6833 - 2s/epoch - 5ms/step\nResNet-20 Testing Accuracy: 0.6833\nResNet-20 Testing Loss: 1.0231\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train and evaluate ResNet-32\nmodel_resnet_32 = create_resnet(num_layers=32)\nmodel_resnet_32.compile(optimizer=SGD(learning_rate=0.1, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_resnet_32.fit(train_images, train_labels, batch_size=64, epochs=10, callbacks=[LearningRateScheduler(lr_schedule)])\nscores_resnet_32 = model_resnet_32.evaluate(train_images, train_labels, verbose=0)\nprint(\"ResNet-32 Training Accuracy:\", scores_resnet_32[1])\nprint(\"ResNet-32 Training Loss:\", scores_resnet_32[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:54:12.203990Z","iopub.execute_input":"2023-11-02T06:54:12.204782Z","iopub.status.idle":"2023-11-02T06:58:09.230274Z","shell.execute_reply.started":"2023-11-02T06:54:12.204739Z","shell.execute_reply":"2023-11-02T06:58:09.229272Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stdout","text":"Epoch 1/10\n782/782 [==============================] - 27s 28ms/step - loss: 1.6927 - accuracy: 0.3575 - lr: 0.1000\nEpoch 2/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.2870 - accuracy: 0.5300 - lr: 0.1000\nEpoch 3/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.0782 - accuracy: 0.6131 - lr: 0.1000\nEpoch 4/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.9660 - accuracy: 0.6545 - lr: 0.1000\nEpoch 5/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.8601 - accuracy: 0.6945 - lr: 0.1000\nEpoch 6/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.7811 - accuracy: 0.7263 - lr: 0.1000\nEpoch 7/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.7173 - accuracy: 0.7495 - lr: 0.1000\nEpoch 8/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.6693 - accuracy: 0.7652 - lr: 0.1000\nEpoch 9/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.6288 - accuracy: 0.7810 - lr: 0.1000\nEpoch 10/10\n782/782 [==============================] - 22s 28ms/step - loss: 0.5887 - accuracy: 0.7980 - lr: 0.1000\nResNet-32 Training Accuracy: 0.703540027141571\nResNet-32 Training Loss: 0.9248278141021729\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate ResNet-20 on the testing data with integer labels\ntest_loss_resnet_32, test_acc_resnet_32 = model_resnet_32.evaluate(test_images, test_labels, verbose=2)\nprint(f'ResNet-32 Testing Accuracy: {test_acc_resnet_32:.4f}')\nprint(f'ResNet-32 Testing Loss: {test_loss_resnet_32:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:58:09.231451Z","iopub.execute_input":"2023-11-02T06:58:09.231749Z","iopub.status.idle":"2023-11-02T06:58:11.293596Z","shell.execute_reply.started":"2023-11-02T06:58:09.231724Z","shell.execute_reply":"2023-11-02T06:58:11.292720Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"313/313 - 2s - loss: 1.0830 - accuracy: 0.6669 - 2s/epoch - 5ms/step\nResNet-32 Testing Accuracy: 0.6669\nResNet-32 Testing Loss: 1.0830\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Using the Adam Optimizer**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam  # Use the legacy optimizer","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:58:11.294768Z","iopub.execute_input":"2023-11-02T06:58:11.295075Z","iopub.status.idle":"2023-11-02T06:58:11.299645Z","shell.execute_reply.started":"2023-11-02T06:58:11.295047Z","shell.execute_reply":"2023-11-02T06:58:11.298632Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam  # Use the legacy optimizer\n# Initialize the legacy Adam optimizer\nadam = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n\n\n# Train and evaluate BaseNet-32 with the Adam optimizer\nmodel_base_32_adam = create_base_net(num_layers=32)\nmodel_base_32_adam.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_base_32_adam.fit(train_images, train_labels, batch_size=64, epochs=10, callbacks=[LearningRateScheduler(lr_schedule)])\nscores_base_32_adam = model_base_32_adam.evaluate(train_images, train_labels, verbose=0)\nprint(\"BaseNet-32 (Adam) Training Accuracy:\", scores_base_32_adam[1])\nprint(\"BaseNet-32 (Adam) Training Loss:\", scores_base_32_adam[0])\n\ntest_loss_base_32_adam, test_acc_base_32_adam = model_base_32_adam.evaluate(test_images, test_labels, verbose=2)\nprint(f'BaseNet-32 (Adam) Testing Accuracy: {test_acc_base_32_adam:.4f}')\nprint(f'BaseNet-32 (Adam) Testing Loss: {test_loss_base_32_adam:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:58:11.300847Z","iopub.execute_input":"2023-11-02T06:58:11.301114Z","iopub.status.idle":"2023-11-02T07:01:48.558525Z","shell.execute_reply.started":"2023-11-02T06:58:11.301091Z","shell.execute_reply":"2023-11-02T07:01:48.557609Z"},"trusted":true},"execution_count":146,"outputs":[{"name":"stdout","text":"Epoch 1/10\n782/782 [==============================] - 21s 25ms/step - loss: 2.1688 - accuracy: 0.1746 - lr: 0.1000\nEpoch 2/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.1445 - accuracy: 0.1791 - lr: 0.1000\nEpoch 3/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.1418 - accuracy: 0.1690 - lr: 0.1000\nEpoch 4/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.0912 - accuracy: 0.1835 - lr: 0.1000\nEpoch 5/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.0887 - accuracy: 0.1853 - lr: 0.1000\nEpoch 6/10\n782/782 [==============================] - 20s 25ms/step - loss: 2.0805 - accuracy: 0.1910 - lr: 0.1000\nEpoch 7/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.0565 - accuracy: 0.1919 - lr: 0.1000\nEpoch 8/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.0677 - accuracy: 0.1962 - lr: 0.1000\nEpoch 9/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.0611 - accuracy: 0.1962 - lr: 0.1000\nEpoch 10/10\n782/782 [==============================] - 19s 25ms/step - loss: 2.0766 - accuracy: 0.1912 - lr: 0.1000\nBaseNet-32 (Adam) Training Accuracy: 0.09997999668121338\nBaseNet-32 (Adam) Training Loss: 29.625850677490234\n313/313 - 1s - loss: 29.6710 - accuracy: 0.1003 - 1s/epoch - 5ms/step\nBaseNet-32 (Adam) Testing Accuracy: 0.1003\nBaseNet-32 (Adam) Testing Loss: 29.6710\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize the legacy Adam optimizer\nadam = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n\n\n# Train and evaluate ResNet-32 with the legacy Adam optimizer\nmodel_resnet_32_adam = create_resnet(num_layers=32)\nmodel_resnet_32_adam.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_resnet_32_adam.fit(train_images, train_labels, batch_size=64, epochs=10, callbacks=[LearningRateScheduler(lr_schedule)])\nscores_resnet_32_adam = model_resnet_32_adam.evaluate(train_images, train_labels, verbose=0)\nprint(\"ResNet-32 (Adam) Training Accuracy:\", scores_resnet_32_adam[1])\nprint(\"ResNet-32 (Adam) Training Loss:\", scores_resnet_32_adam[0])\n\ntest_loss_resnet_32_adam, test_acc_resnet_32_adam = model_resnet_32_adam.evaluate(test_images, test_labels, verbose=2)\nprint(f'ResNet-32 (Adam) Testing Accuracy: {test_acc_resnet_32_adam:.4f}')\nprint(f'ResNet-32 (Adam) Testing Loss: {test_loss_resnet_32_adam:.4f}')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T07:01:48.559854Z","iopub.execute_input":"2023-11-02T07:01:48.560474Z","iopub.status.idle":"2023-11-02T07:05:46.919339Z","shell.execute_reply.started":"2023-11-02T07:01:48.560436Z","shell.execute_reply":"2023-11-02T07:05:46.918320Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stdout","text":"Epoch 1/10\n782/782 [==============================] - 24s 28ms/step - loss: 2.0801 - accuracy: 0.2012 - lr: 0.1000\nEpoch 2/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.7365 - accuracy: 0.3361 - lr: 0.1000\nEpoch 3/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.6310 - accuracy: 0.3879 - lr: 0.1000\nEpoch 4/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.9037 - accuracy: 0.3020 - lr: 0.1000\nEpoch 5/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.7161 - accuracy: 0.3277 - lr: 0.1000\nEpoch 6/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.5743 - accuracy: 0.3959 - lr: 0.1000\nEpoch 7/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.4757 - accuracy: 0.4424 - lr: 0.1000\nEpoch 8/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.4037 - accuracy: 0.4772 - lr: 0.1000\nEpoch 9/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.3381 - accuracy: 0.5074 - lr: 0.1000\nEpoch 10/10\n782/782 [==============================] - 22s 28ms/step - loss: 1.2709 - accuracy: 0.5365 - lr: 0.1000\nResNet-32 (Adam) Training Accuracy: 0.3862600028514862\nResNet-32 (Adam) Training Loss: 2.1829288005828857\n313/313 - 2s - loss: 2.2046 - accuracy: 0.3766 - 2s/epoch - 5ms/step\nResNet-32 (Adam) Testing Accuracy: 0.3766\nResNet-32 (Adam) Testing Loss: 2.2046\n","output_type":"stream"}]}]}